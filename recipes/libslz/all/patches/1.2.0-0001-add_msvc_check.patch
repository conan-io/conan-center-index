diff --git a/a/src/slz.c b/b/src/slz.c
index fae493d..e381246 100644
--- a/a/src/slz.c
+++ b/b/src/slz.c
@@ -373,7 +373,7 @@ static void copy_lit_huff(struct slz_stream *strm, const unsigned char *buf, uin
  */
 static inline uint32_t slz_hash(uint32_t a)
 {
-#if defined(__ARM_FEATURE_CRC32)
+#if defined(__ARM_FEATURE_CRC32) && !defined _MSC_VER
 	__asm__ volatile("crc32w %w0,%w0,%w1" : "+r"(a) : "r"(0));
 	return a >> (32 - HASH_BITS);
 #else
@@ -415,7 +415,7 @@ static inline long memmatch(const unsigned char *a, const unsigned char *b, long
 		len += sizeof(long);
 	}
 
-#if defined(__x86_64__) || defined(__i386__) || defined(__i486__) || defined(__i586__) || defined(__i686__)
+#if (defined(__x86_64__) || defined(__i386__) || defined(__i486__) || defined(__i586__) || defined(__i686__)) && !(defined _MSC_VER)
 	/* x86 has bsf. We know that xor is non-null here */
 	asm("bsf %1,%0\n" : "=r"(xor) : "0" (xor));
 	return len + xor / 8;
@@ -536,8 +536,9 @@ long slz_rfc1951_encode(struct slz_stream *strm, unsigned char *out, const unsig
 		word = *(uint32_t *)&in[pos];
 #endif
 		h = slz_hash(word);
+#if !(defined _MSC_VER)
 		asm volatile ("" ::); // prevent gcc from trying to be smart with the prefetch
-
+#endif
 		if (sizeof(long) >= 8) {
 			ent = refs[h].by64;
 			last = (uint32_t)ent;
@@ -868,7 +869,7 @@ static const unsigned char gzip_hdr[] = { 0x1F, 0x8B,   // ID1, ID2
 
 static inline uint32_t crc32_char(uint32_t crc, uint8_t x)
 {
-#if defined(__ARM_FEATURE_CRC32)
+#if defined(__ARM_FEATURE_CRC32) && !(defined _MSC_VER)
 	crc = ~crc;
 	__asm__ volatile("crc32b %w0,%w0,%w1" : "+r"(crc) : "r"(x));
 	crc = ~crc;
@@ -880,7 +881,7 @@ static inline uint32_t crc32_char(uint32_t crc, uint8_t x)
 
 static inline uint32_t crc32_uint32(uint32_t data)
 {
-#if defined(__ARM_FEATURE_CRC32)
+#if defined(__ARM_FEATURE_CRC32)  && !(defined _MSC_VER)
 	__asm__ volatile("crc32w %w0,%w0,%w1" : "+r"(data) : "r"(~0UL));
 	data = ~data;
 #else
@@ -911,7 +912,7 @@ uint32_t slz_crc32_by4(uint32_t crc, const unsigned char *buf, int len)
 
 	while (buf <= end - 16) {
 #ifdef UNALIGNED_LE_OK
-#if defined(__ARM_FEATURE_CRC32)
+#if defined(__ARM_FEATURE_CRC32) && !(defined _MSC_VER)
 		crc = ~crc;
 		__asm__ volatile("crc32w %w0,%w0,%w1" : "+r"(crc) : "r"(*(uint32_t*)(buf)));
 		__asm__ volatile("crc32w %w0,%w0,%w1" : "+r"(crc) : "r"(*(uint32_t*)(buf + 4)));
