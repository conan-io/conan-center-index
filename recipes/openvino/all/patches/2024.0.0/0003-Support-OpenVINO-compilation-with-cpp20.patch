diff --git a/.github/workflows/linux_conditional_compilation.yml b/.github/workflows/linux_conditional_compilation.yml
index 4f2d7d8ec9..f74802072c 100644
--- a/.github/workflows/linux_conditional_compilation.yml
+++ b/.github/workflows/linux_conditional_compilation.yml
@@ -152,6 +152,7 @@ jobs:
         run: |
           cmake \
             -G "${{ env.CMAKE_GENERATOR }}" \
+            -DCMAKE_CXX_STANDARD=20 \
             -DBUILD_SHARED_LIBS=OFF \
             -DENABLE_TESTS=ON \
             -DENABLE_CPPLINT=OFF \
diff --git a/.github/workflows/windows_conditional_compilation.yml b/.github/workflows/windows_conditional_compilation.yml
index 6a47f620e7..ead6c37c87 100644
--- a/.github/workflows/windows_conditional_compilation.yml
+++ b/.github/workflows/windows_conditional_compilation.yml
@@ -147,6 +147,7 @@ jobs:
         run: |
           cmake -G "${{ env.CMAKE_GENERATOR }}" `
             -DBUILD_SHARED_LIBS=OFF `
+            -DCMAKE_CXX_STANDARD=20 `
             -DENABLE_TESTS=ON `
             -DENABLE_CPPLINT=OFF `
             -DENABLE_NCC_STYLE=OFF `
diff --git a/docs/snippets/CMakeLists.txt b/docs/snippets/CMakeLists.txt
index 89c39d706d..415f1dea88 100644
--- a/docs/snippets/CMakeLists.txt
+++ b/docs/snippets/CMakeLists.txt
@@ -15,6 +15,10 @@ if(UNUSED_BUT_SET_VARIABLE_SUPPORTED)
     ov_add_compiler_flags(-Wno-unused-but-set-variable)
 endif()

+if((CMAKE_COMPILER_IS_GNUCXX OR OV_COMPILER_IS_CLANG) AND CMAKE_CXX_STANDARD GREATER_EQUAL 20)
+    set(CMAKE_CXX_FLAGS "-Wno-error=deprecated ${CMAKE_CXX_FLAGS}")
+endif()
+
 file(GLOB SOURCES "${CMAKE_CURRENT_SOURCE_DIR}/*.cpp"
                   "${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp"
                   "${CMAKE_CURRENT_SOURCE_DIR}/src/*.c")
diff --git a/samples/cpp/hello_classification/main.cpp b/samples/cpp/hello_classification/main.cpp
index b0624b9a54..940ab918dd 100644
--- a/samples/cpp/hello_classification/main.cpp
+++ b/samples/cpp/hello_classification/main.cpp
@@ -28,7 +28,8 @@ int tmain(int argc, tchar* argv[]) {

         // -------- Parsing and validation of input arguments --------
         if (argc != 4) {
-            slog::info << "Usage : " << argv[0] << " <path_to_model> <path_to_image> <device_name>" << slog::endl;
+            slog::info << "Usage : " << TSTRING2STRING(argv[0]) << " <path_to_model> <path_to_image> <device_name>"
+                       << slog::endl;
             return EXIT_FAILURE;
         }

diff --git a/src/common/low_precision_transformations/CMakeLists.txt b/src/common/low_precision_transformations/CMakeLists.txt
index 215cb74de0..a325407d82 100644
--- a/src/common/low_precision_transformations/CMakeLists.txt
+++ b/src/common/low_precision_transformations/CMakeLists.txt
@@ -16,6 +16,9 @@ source_group("src" FILES ${LIBRARY_SRC})
 source_group("include" FILES ${PUBLIC_HEADERS})

 # Create library
+if((CMAKE_COMPILER_IS_GNUCXX OR OV_COMPILER_IS_CLANG) AND CMAKE_CXX_STANDARD GREATER_EQUAL 20)
+    set(CMAKE_CXX_FLAGS "-Wno-error=deprecated ${CMAKE_CXX_FLAGS}")
+endif()

 add_library(${TARGET_NAME}_obj OBJECT
             ${LIBRARY_SRC}
diff --git a/src/common/snippets/CMakeLists.txt b/src/common/snippets/CMakeLists.txt
index b3d2db77b7..dcde389cde 100644
--- a/src/common/snippets/CMakeLists.txt
+++ b/src/common/snippets/CMakeLists.txt
@@ -16,6 +16,9 @@ source_group("src" FILES ${LIBRARY_SRC})
 source_group("include" FILES ${PUBLIC_HEADERS})

 # Create static library
+if((CMAKE_COMPILER_IS_GNUCXX OR OV_COMPILER_IS_CLANG) AND CMAKE_CXX_STANDARD GREATER_EQUAL 20)
+    set(CMAKE_CXX_FLAGS "-Wno-error=deprecated ${CMAKE_CXX_FLAGS}")
+endif()

 add_library(${TARGET_NAME} STATIC
             ${LIBRARY_SRC}
diff --git a/src/common/transformations/CMakeLists.txt b/src/common/transformations/CMakeLists.txt
index c4c4ccaa9b..1d398b0054 100644
--- a/src/common/transformations/CMakeLists.txt
+++ b/src/common/transformations/CMakeLists.txt
@@ -16,6 +16,9 @@ source_group("src" FILES ${LIBRARY_SRC})
 source_group("include" FILES ${PUBLIC_HEADERS})

 # Create library
+if((CMAKE_COMPILER_IS_GNUCXX OR OV_COMPILER_IS_CLANG) AND CMAKE_CXX_STANDARD GREATER_EQUAL 20)
+    set(CMAKE_CXX_FLAGS "-Wno-error=deprecated ${CMAKE_CXX_FLAGS}")
+endif()

 add_library(${TARGET_NAME}_obj OBJECT ${LIBRARY_SRC} ${PUBLIC_HEADERS})
 target_compile_definitions(${TARGET_NAME}_obj PRIVATE IMPLEMENT_OPENVINO_API)
diff --git a/src/common/transformations/include/transformations/rt_info/nms_selected_indices.hpp b/src/common/transformations/include/transformations/rt_info/nms_selected_indices.hpp
index 0719a5347c..28fa98d324 100644
--- a/src/common/transformations/include/transformations/rt_info/nms_selected_indices.hpp
+++ b/src/common/transformations/include/transformations/rt_info/nms_selected_indices.hpp
@@ -21,7 +21,7 @@ TRANSFORMATIONS_API bool has_nms_selected_indices(const Node* node);

 TRANSFORMATIONS_API void set_nms_selected_indices(Node* node);

-class TRANSFORMATIONS_API NmsSelectedIndices : ov::RuntimeAttribute {
+class TRANSFORMATIONS_API NmsSelectedIndices : public ov::RuntimeAttribute {
 public:
     OPENVINO_RTTI("nms_selected_indices", "0");
     NmsSelectedIndices() = default;
diff --git a/src/core/tests/matcher_pass.cpp b/src/core/tests/matcher_pass.cpp
index ae0b6d911c..0ac381a531 100644
--- a/src/core/tests/matcher_pass.cpp
+++ b/src/core/tests/matcher_pass.cpp
@@ -25,7 +25,7 @@ public:
         auto m_relu1 = ov::pass::pattern::wrap_type<ov::op::v0::Relu>(pattern::consumers_count(1));
         auto m_relu2 = ov::pass::pattern::wrap_type<ov::op::v0::Relu>({m_relu1});

-        ov::graph_rewrite_callback callback = [=](pattern::Matcher& m) {
+        ov::graph_rewrite_callback callback = [m_relu1, this](pattern::Matcher& m) {
             // Map that helps to connect labels with matched outputs
             auto& node_to_output = m.get_pattern_value_map();

diff --git a/src/frontends/paddle/src/CMakeLists.txt b/src/frontends/paddle/src/CMakeLists.txt
index af0cf0373a..57241ae95a 100644
--- a/src/frontends/paddle/src/CMakeLists.txt
+++ b/src/frontends/paddle/src/CMakeLists.txt
@@ -2,6 +2,10 @@
 # SPDX-License-Identifier: Apache-2.0
 #

+if((CMAKE_COMPILER_IS_GNUCXX OR OV_COMPILER_IS_CLANG) AND CMAKE_CXX_STANDARD GREATER_EQUAL 20)
+    set(CMAKE_CXX_FLAGS "-Wno-error=deprecated ${CMAKE_CXX_FLAGS}")
+endif()
+
 ov_add_frontend(NAME paddle
                 LINKABLE_FRONTEND
                 PROTOBUF_REQUIRED
diff --git a/src/frontends/pytorch/src/CMakeLists.txt b/src/frontends/pytorch/src/CMakeLists.txt
index 814d820b5c..7fb8c4ae50 100644
--- a/src/frontends/pytorch/src/CMakeLists.txt
+++ b/src/frontends/pytorch/src/CMakeLists.txt
@@ -2,6 +2,10 @@
 # SPDX-License-Identifier: Apache-2.0
 #

+if((CMAKE_COMPILER_IS_GNUCXX OR OV_COMPILER_IS_CLANG) AND CMAKE_CXX_STANDARD GREATER_EQUAL 20)
+    set(CMAKE_CXX_FLAGS "-Wno-error=deprecated ${CMAKE_CXX_FLAGS}")
+endif()
+
 ov_add_frontend(NAME pytorch
                 LINKABLE_FRONTEND
                 SHUTDOWN_PROTOBUF
diff --git a/src/frontends/tensorflow/src/variables_index.cpp b/src/frontends/tensorflow/src/variables_index.cpp
index 2dcf3faf9e..3d97022bc6 100644
--- a/src/frontends/tensorflow/src/variables_index.cpp
+++ b/src/frontends/tensorflow/src/variables_index.cpp
@@ -228,11 +228,11 @@ bool VariablesIndex::read_variables(std::ifstream& vi_stream, const std::wstring
         }
         if (m_mmap_enabled) {
             m_data_files[shard].mmap = load_mmap_object(fullPath);
-            FRONT_END_GENERAL_CHECK(m_data_files[shard].mmap->data(), L"Variable index data cannot be mapped");
+            FRONT_END_GENERAL_CHECK(m_data_files[shard].mmap->data(), "Variable index data cannot be mapped");
         } else {
             m_data_files[shard].stream = std::shared_ptr<std::ifstream>(
                 new std::ifstream(fullPath.c_str(), std::ifstream::in | std::ifstream::binary));
-            FRONT_END_GENERAL_CHECK(m_data_files[shard].stream->is_open(), L"Variable index data file does not exist");
+            FRONT_END_GENERAL_CHECK(m_data_files[shard].stream->is_open(), "Variable index data file does not exist");
         }
     }

diff --git a/src/inference/tests/functional/caching_test.cpp b/src/inference/tests/functional/caching_test.cpp
index 1b45c2bd4a..c1a7d685f4 100644
--- a/src/inference/tests/functional/caching_test.cpp
+++ b/src/inference/tests/functional/caching_test.cpp
@@ -2359,9 +2359,7 @@ TEST_P(CachingTest, LoadBATCHWithConfig) {
     EXPECT_CALL(*mockPlugin, get_property(ov::internal::caching_properties.name(), _)).Times(AnyNumber());
     EXPECT_CALL(*mockPlugin, get_property(ov::hint::performance_mode.name(), _))
         .Times(AnyNumber())
-        .WillRepeatedly(Return([] {
-            return ov::hint::PerformanceMode::THROUGHPUT;
-        }));
+        .WillRepeatedly(Return(ov::hint::PerformanceMode::THROUGHPUT));
     if (m_remoteContext) {
         return;  // skip the remote Context test for Auto plugin
     }
@@ -2490,4 +2488,4 @@ INSTANTIATE_TEST_SUITE_P(CacheTestWithProxyEnabled,
                          CacheTestWithProxyEnabled,
                          ::testing::Combine(::testing::ValuesIn(loadVariants), ::testing::ValuesIn(cacheFolders)),
                          getTestCaseName);
-#endif
\ No newline at end of file
+#endif
diff --git a/src/plugins/auto_batch/src/sync_infer_request.cpp b/src/plugins/auto_batch/src/sync_infer_request.cpp
index c766c521ce..707adedc3b 100644
--- a/src/plugins/auto_batch/src/sync_infer_request.cpp
+++ b/src/plugins/auto_batch/src/sync_infer_request.cpp
@@ -160,4 +160,4 @@ std::vector<ov::ProfilingInfo> SyncInferRequest::get_profiling_info() const {
     return m_batched_request_wrapper->_infer_request_batched->get_profiling_info();
 }
 }  // namespace autobatch_plugin
-}  // namespace ov
\ No newline at end of file
+}  // namespace ov
diff --git a/src/plugins/intel_cpu/CMakeLists.txt b/src/plugins/intel_cpu/CMakeLists.txt
index 3a15194061..962ba21c0e 100644
--- a/src/plugins/intel_cpu/CMakeLists.txt
+++ b/src/plugins/intel_cpu/CMakeLists.txt
@@ -8,6 +8,10 @@ endif()

 set(TARGET_NAME "openvino_intel_cpu_plugin")

+if((CMAKE_COMPILER_IS_GNUCXX OR OV_COMPILER_IS_CLANG) AND CMAKE_CXX_STANDARD GREATER_EQUAL 20)
+    set(CMAKE_CXX_FLAGS "-Wno-error=deprecated ${CMAKE_CXX_FLAGS}")
+endif()
+
 if(CMAKE_CXX_COMPILER_ID STREQUAL "MSVC")
     # C4267, 4244 issues from oneDNN headers conversion from 'XXX' to 'YYY', possible loss of data
     ov_add_compiler_flags(/wd4018)
@@ -205,7 +209,7 @@ if(BUILD_SHARED_LIBS)
             $<TARGET_PROPERTY:openvino::conditional_compilation,INTERFACE_INCLUDE_DIRECTORIES>)

     target_include_directories(${TARGET_NAME}_obj SYSTEM PUBLIC $<TARGET_PROPERTY:dnnl,INCLUDE_DIRECTORIES>)
-    
+
     if(ENABLE_MLAS_FOR_CPU)
         target_include_directories(${TARGET_NAME}_obj SYSTEM PUBLIC $<TARGET_PROPERTY:mlas,INCLUDE_DIRECTORIES>)
     endif()
diff --git a/src/plugins/intel_cpu/src/cache/multi_cache.h b/src/plugins/intel_cpu/src/cache/multi_cache.h
index 746499bd9b..8225f5ed0f 100644
--- a/src/plugins/intel_cpu/src/cache/multi_cache.h
+++ b/src/plugins/intel_cpu/src/cache/multi_cache.h
@@ -41,10 +41,14 @@ public:
     *       Also the builder type is used for the ValueType deduction
     * @return result of the operation which is a pair of the requested object of ValType and the status of whether the cache hit or miss occurred
     */
-
-    template<typename KeyType, typename BuilderType, typename ValueType = typename std::result_of<BuilderType&(const KeyType&)>::type>
-    typename CacheEntry<KeyType, ValueType>::ResultType
-    getOrCreate(const KeyType& key, BuilderType builder) {
+    template <typename KeyType,
+              typename BuilderType,
+#if (defined(_MSVC_LANG) && (_MSVC_LANG > 201703L)) || (defined(__cplusplus) && (__cplusplus > 201703L))
+              typename ValueType = std::invoke_result_t<BuilderType&, const KeyType&>>
+#else
+              typename ValueType = typename std::result_of<BuilderType&(const KeyType&)>::type>
+#endif
+    typename CacheEntry<KeyType, ValueType>::ResultType getOrCreate(const KeyType& key, BuilderType builder) {
         auto entry = getEntry<KeyType, ValueType>();
         return entry->getOrCreate(key, std::move(builder));
     }
diff --git a/src/plugins/intel_cpu/src/graph.cpp b/src/plugins/intel_cpu/src/graph.cpp
index 39a72bd80a..e1362e3302 100644
--- a/src/plugins/intel_cpu/src/graph.cpp
+++ b/src/plugins/intel_cpu/src/graph.cpp
@@ -1093,6 +1093,17 @@ private:
 #endif

 #if (OV_THREAD == OV_THREAD_TBB || OV_THREAD == OV_THREAD_TBB_AUTO || OV_THREAD == OV_THREAD_OMP)
+
+#    if (defined(_MSVC_LANG) && (_MSVC_LANG > 201703L)) || (defined(__cplusplus) && (__cplusplus > 201703L))
+#        define ov_memory_order_release std::memory_order_release
+#        define ov_memory_order_relaxed std::memory_order_relaxed
+#        define ov_memory_order_acquire std::memory_order_acquire
+#    else
+#        define ov_memory_order_release std::memory_order::memory_order_release
+#        define ov_memory_order_relaxed std::memory_order::memory_order_relaxed
+#        define ov_memory_order_acquire std::memory_order::memory_order_acquire
+#    endif
+
 class UpdateNodesBase : public IUpdateNodes {
 public:
     explicit UpdateNodesBase(std::vector<NodePtr>& executableGraphNodes) : m_executableGraphNodes(executableGraphNodes) {}
@@ -1103,22 +1114,22 @@ public:
                 if (node->isDynamicNode()) {
                     node->updateShapes();
                 }
-                m_prepareCounter.store(i, std::memory_order::memory_order_release);
+                m_prepareCounter.store(i, ov_memory_order_release);
             }
         }
         catch(...) {
-            m_completion.store(true, std::memory_order::memory_order_relaxed);
+            m_completion.store(true, ov_memory_order_relaxed);
             throw;
         }
-        m_prepareCounter.store(stop_indx, std::memory_order::memory_order_relaxed);
-        m_completion.store(true, std::memory_order::memory_order_release);
+        m_prepareCounter.store(stop_indx, ov_memory_order_relaxed);
+        m_completion.store(true, ov_memory_order_release);
     }

     void updateDynParams(size_t node_indx, size_t /*unused*/) {
         size_t local_counter = node_indx;
         while (true) {
-            const bool completion = m_completion.load(std::memory_order::memory_order_acquire);
-            const size_t prepareCounter = m_prepareCounter.load(std::memory_order::memory_order_relaxed);
+            const bool completion = m_completion.load(ov_memory_order_acquire);
+            const size_t prepareCounter = m_prepareCounter.load(ov_memory_order_relaxed);
             if (completion && local_counter == prepareCounter) {
                 break;
             }
diff --git a/src/plugins/intel_cpu/src/nodes/executors/fullyconnected_implementations.cpp b/src/plugins/intel_cpu/src/nodes/executors/fullyconnected_implementations.cpp
index 0f656c7049..cae4a605f6 100644
--- a/src/plugins/intel_cpu/src/nodes/executors/fullyconnected_implementations.cpp
+++ b/src/plugins/intel_cpu/src/nodes/executors/fullyconnected_implementations.cpp
@@ -244,7 +244,10 @@ const std::vector<ExecutorImplementation<FCAttrs>>& getImplementations() {
                 return true;
             },
             // create
-            [](const FCAttrs& attrs, const PostOps& postOps, const MemoryArgs& memory, ExecutorContext::CPtr context) {
+            [](const FCAttrs& attrs,
+               const PostOps& postOps,
+               const MemoryArgs& memory,
+               ExecutorContext::CPtr context) -> std::shared_ptr<Executor> {
                 struct ConvolutionInstantiator {
                     std::shared_ptr<DnnlConvolutionPrimitive> operator()(
                         const MemoryArgs& memory,
diff --git a/src/plugins/intel_cpu/src/nodes/inverse.cpp b/src/plugins/intel_cpu/src/nodes/inverse.cpp
index 93f0df2948..04c283fc2f 100644
--- a/src/plugins/intel_cpu/src/nodes/inverse.cpp
+++ b/src/plugins/intel_cpu/src/nodes/inverse.cpp
@@ -153,7 +153,7 @@ void Inverse::lu_decomposition(const T* data,

         // Find maximum value pivot - non-parallel
         for (size_t i = (k + 1) * m_side, j = k + 1; i < m_side_squared; i += m_side, ++j) {
-            if (abs(U[i + k]) > abs(U[pivot_idx + k])) {
+            if (std::abs(U[i + k]) > std::abs(U[pivot_idx + k])) {
                 pivot_row = j;
                 pivot_idx = pivot_row * m_side;
             }
diff --git a/src/plugins/intel_cpu/src/nodes/kernels/x64/jit_kernel.hpp b/src/plugins/intel_cpu/src/nodes/kernels/x64/jit_kernel.hpp
index e837dc7fdf..ecc3688c68 100644
--- a/src/plugins/intel_cpu/src/nodes/kernels/x64/jit_kernel.hpp
+++ b/src/plugins/intel_cpu/src/nodes/kernels/x64/jit_kernel.hpp
@@ -700,6 +700,9 @@ private:
     std::unordered_map<size_t, std::unique_ptr<jit_emitter>> _emitters;
 };

+template <>
+const Xbyak::Reg64& jit_kernel::reserve<Xbyak::Reg64>();
+
 template<typename T>
 void jit_kernel::copy(const Xbyak::Reg64& dst,
                       const Xbyak::Reg64& src,
diff --git a/src/plugins/intel_gpu/CMakeLists.txt b/src/plugins/intel_gpu/CMakeLists.txt
index e48c985ad7..18a941ca79 100644
--- a/src/plugins/intel_gpu/CMakeLists.txt
+++ b/src/plugins/intel_gpu/CMakeLists.txt
@@ -8,6 +8,10 @@ endif()

 set (TARGET_NAME "openvino_intel_gpu_plugin")

+if((CMAKE_COMPILER_IS_GNUCXX OR OV_COMPILER_IS_CLANG) AND CMAKE_CXX_STANDARD GREATER_EQUAL 20)
+    set(CMAKE_CXX_FLAGS "-Wno-error=deprecated ${CMAKE_CXX_FLAGS}")
+endif()
+
 if(CMAKE_COMPILER_IS_GNUCXX)
     ov_add_compiler_flags(-Wno-strict-aliasing)
 endif()
diff --git a/src/plugins/intel_gpu/src/graph/graph_optimizer/reorder_inputs.cpp b/src/plugins/intel_gpu/src/graph/graph_optimizer/reorder_inputs.cpp
index 0148026b6c..20b229ad9c 100644
--- a/src/plugins/intel_gpu/src/graph/graph_optimizer/reorder_inputs.cpp
+++ b/src/plugins/intel_gpu/src/graph/graph_optimizer/reorder_inputs.cpp
@@ -689,16 +689,16 @@ void reorder_inputs::run(program& p, layout_optimizer& lo, reorder_factory& rf)
     }

     GPU_DEBUG_IF(debug_config->verbose >= 2) {
-        reorder_cnt total_reorder_count = std::accumulate(
-            p.get_processing_order().begin(),
-            p.get_processing_order().end(),
-            reorder_cnt{ 0, 0 },
-            [&](reorder_cnt& total, program_node* node) {
-            if (fmt_map.count(node) == 0 || fmt_map.at(node) == format::any)
-                return total;
-            auto count = count_reorders(fmt_map, lo, node);
-            return reorder_cnt{ total.number + count.number, total.total_sizes + count.total_sizes };
-        });
+        reorder_cnt total_reorder_count =
+            std::accumulate(p.get_processing_order().begin(),
+                            p.get_processing_order().end(),
+                            reorder_cnt{0, 0},
+                            [&](reorder_cnt total, program_node* node) {
+                                if (fmt_map.count(node) == 0 || fmt_map.at(node) == format::any)
+                                    return total;
+                                auto count = count_reorders(fmt_map, lo, node);
+                                return reorder_cnt{total.number + count.number, total.total_sizes + count.total_sizes};
+                            });
         // Divide results by two as above function will each reorder from both sides
         GPU_DEBUG_LOG_PASS << "Total number of reorders: " << total_reorder_count.number / 2 << std::endl;
         GPU_DEBUG_LOG_PASS << "Total elements count of all reorders: " << total_reorder_count.total_sizes / 2 << std::endl;
diff --git a/src/plugins/intel_gpu/src/kernel_selector/auto_tuner.cpp b/src/plugins/intel_gpu/src/kernel_selector/auto_tuner.cpp
index a5d0711f61..d71a6834e8 100644
--- a/src/plugins/intel_gpu/src/kernel_selector/auto_tuner.cpp
+++ b/src/plugins/intel_gpu/src/kernel_selector/auto_tuner.cpp
@@ -36,6 +36,27 @@
 #include <dlfcn.h>
 #endif

+#if __cplusplus > 201703L
+
+// Add operators `==` and `!=` for rapidjson::GenericMemberIterator for non const iterator when build with C++20,
+// is more strict regarding type checks.
+namespace rapidjson {
+
+template <typename Encoding, typename Allocator>
+inline bool operator==(GenericMemberIterator<false, Encoding, Allocator> lhs,
+                       GenericMemberIterator<false, Encoding, Allocator> rhs) {
+    return static_cast<GenericMemberIterator<true, Encoding, Allocator>>(lhs) ==
+           static_cast<GenericMemberIterator<true, Encoding, Allocator>>(rhs);
+}
+
+template <typename Encoding, typename Allocator>
+inline bool operator!=(GenericMemberIterator<false, Encoding, Allocator> lhs,
+                       GenericMemberIterator<false, Encoding, Allocator> rhs) {
+    return !(lhs == rhs);
+}
+}  // namespace rapidjson
+#endif
+
 namespace kernel_selector {

 class TuningCache::Impl {
diff --git a/src/plugins/intel_gpu/src/kernel_selector/kernel_selector_common.cpp b/src/plugins/intel_gpu/src/kernel_selector/kernel_selector_common.cpp
index 6caa5e75a4..3a14e9d802 100644
--- a/src/plugins/intel_gpu/src/kernel_selector/kernel_selector_common.cpp
+++ b/src/plugins/intel_gpu/src/kernel_selector/kernel_selector_common.cpp
@@ -612,10 +612,8 @@ std::string toString_v2(const DataTensor& tensor) {
     std::stringstream s;
     s << toString(tensor.GetDType()) << "_";
     s << toString(tensor.GetLayout());
-    int i = 0;
     for (auto dim : tensor.GetDims()) {
         s << "_v" << dim.v << "_p" << dim.pad.before << "_" << dim.pad.after;
-        i++;
     }
     return s.str();
 }
diff --git a/src/plugins/intel_gpu/tests/unit/module_tests/primitive_comparison_test.cpp b/src/plugins/intel_gpu/tests/unit/module_tests/primitive_comparison_test.cpp
index 0390593b59..3e0f608a9e 100644
--- a/src/plugins/intel_gpu/tests/unit/module_tests/primitive_comparison_test.cpp
+++ b/src/plugins/intel_gpu/tests/unit/module_tests/primitive_comparison_test.cpp
@@ -11,6 +11,13 @@
 #include <intel_gpu/primitives/gather.hpp>
 #include <intel_gpu/primitives/permute.hpp>

+namespace cldnn {
+// For gtest NE compare, class defines only `==` operator. Required when building using C++20
+inline bool operator!=(const range& lhs, const fully_connected& rhs) {
+    return !(lhs.operator==(rhs));
+}
+}  // namespace cldnn
+
 using namespace cldnn;
 using namespace ::tests;

diff --git a/src/tests/test_utils/common_test_utils/src/file_utils.cpp b/src/tests/test_utils/common_test_utils/src/file_utils.cpp
index b1b8b42797..eadaab6b71 100644
--- a/src/tests/test_utils/common_test_utils/src/file_utils.cpp
+++ b/src/tests/test_utils/common_test_utils/src/file_utils.cpp
@@ -192,7 +192,7 @@ std::string getRelativePath(const std::string& from, const std::string& to) {
         output += std::accumulate(mismatch_it.first,
                                   from_vec.end(),
                                   std::string{},
-                                  [&separator](std::string& a, const std::string&) -> std::string {
+                                  [&separator](std::string a, const std::string&) -> std::string {
                                       return a += ".." + separator;
                                   });
     }
@@ -203,7 +203,7 @@ std::string getRelativePath(const std::string& from, const std::string& to) {
     output += std::accumulate(mismatch_it.second,
                               to_vec.end(),
                               std::string{},
-                              [&separator](std::string& a, const std::string& b) -> std::string {
+                              [&separator](std::string a, const std::string& b) -> std::string {
                                   return a.empty() ? a += b : a += separator + b;
                               });
     return output;
diff --git a/thirdparty/itt_collector/sea_itt_lib/sea_itt_lib.cpp b/thirdparty/itt_collector/sea_itt_lib/sea_itt_lib.cpp
index 18196eda17..a764b27e68 100644
--- a/thirdparty/itt_collector/sea_itt_lib/sea_itt_lib.cpp
+++ b/thirdparty/itt_collector/sea_itt_lib/sea_itt_lib.cpp
@@ -327,14 +327,14 @@ SEA_EXPORT int NotifyEvent(iJIT_JVM_EVENT event_type, void* EventSpecificData) {

     switch (event_type) {
     case iJVM_EVENT_TYPE_METHOD_LOAD_FINISHED: {
-        sea::WriteJit(&(uint32_t)methodData->method_id, sizeof(uint32_t));
+        sea::WriteJit(&methodData->method_id, sizeof(uint32_t));
         sea::WriteJit(&methodData->method_load_address, sizeof(void*));
-        sea::WriteJit(&(uint32_t)methodData->method_size, sizeof(uint32_t));
-        sea::WriteJit(&(uint32_t)methodData->line_number_size, sizeof(uint32_t));
+        sea::WriteJit(&methodData->method_size, sizeof(uint32_t));
+        sea::WriteJit(&methodData->line_number_size, sizeof(uint32_t));
         for (unsigned int i = 0; i < methodData->line_number_size; ++i) {
             const LineNumberInfo& lni = methodData->line_number_table[i];
-            sea::WriteJit(&(uint32_t)lni.Offset, sizeof(uint32_t));
-            sea::WriteJit(&(uint32_t)lni.LineNumber, sizeof(uint32_t));
+            sea::WriteJit(&lni.Offset, sizeof(uint32_t));
+            sea::WriteJit(&lni.LineNumber, sizeof(uint32_t));
         }

         const char* strings[] = {methodData->method_name, methodData->class_file_name, methodData->source_file_name};

